{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Preface\n",
        "The reason I created this notebook is to update the way to build the ONNX model of this repo, more specifically, the way the author builds the ONNX model here makes the ONNX model (FaceDetector.onnx) look like it supports dynamic batch size but in fact it is static batch size and even fixed at 1x3x1x1 which makes me encounter many difficulties and almost unable to convert .onnx to TensorRT engine as I want to use for my project. In this notebook, I will update the convert_to_onnx.py file to build a model that supports dynamic batch size. This helps the above errors and helps me to use the model in DeepStream with batch_size > 1 (multiple sources)."
      ],
      "metadata": {
        "id": "wENvRw3m5OKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies\n"
      ],
      "metadata": {
        "id": "ZQAPMt8RuMmo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_cell_1",
        "outputId": "c5ec52d5-85de-448a-fc0a-70a7e27ccf3c"
      },
      "source": [
        "!pip install onnx"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "vNaBkBnSqzsv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNzZJZWikTDD",
        "outputId": "948ab9b4-cf7f-4a31-f17a-da96c18946c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import importlib"
      ],
      "metadata": {
        "id": "WrugBJnCwi3o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load files"
      ],
      "metadata": {
        "id": "rXzXI1FJuR3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the original repository .zip file and unzip it, remember to rename the file if needed."
      ],
      "metadata": {
        "id": "WoEnqdX2uieI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip RetinaFace-master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooqgVmQLq8Ux",
        "outputId": "24000bda-fe75-4c84-919f-b4263619e577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  RetinaFace-master.zip\n",
            "9534698bcfc7f77fedae600b22e7f6bf0616a31e\n",
            "   creating: RetinaFace-master/\n",
            "  inflating: RetinaFace-master/.gitattributes  \n",
            "  inflating: RetinaFace-master/FaceDetector.onnx  \n",
            "  inflating: RetinaFace-master/LICENSE.MIT  \n",
            "  inflating: RetinaFace-master/README.md  \n",
            "  inflating: RetinaFace-master/convert_to_onnx.py  \n",
            "   creating: RetinaFace-master/curve/\n",
            "  inflating: RetinaFace-master/curve/1.jpg  \n",
            "  inflating: RetinaFace-master/curve/FDDB.png  \n",
            "  inflating: RetinaFace-master/curve/Widerface.jpg  \n",
            "  inflating: RetinaFace-master/curve/test.jpg  \n",
            "   creating: RetinaFace-master/data/\n",
            "   creating: RetinaFace-master/data/FDDB/\n",
            "  inflating: RetinaFace-master/data/FDDB/img_list.txt  \n",
            "  inflating: RetinaFace-master/data/__init__.py  \n",
            "  inflating: RetinaFace-master/data/config.py  \n",
            "  inflating: RetinaFace-master/data/data_augment.py  \n",
            "  inflating: RetinaFace-master/data/wider_face.py  \n",
            "  inflating: RetinaFace-master/detect.py  \n",
            "  inflating: RetinaFace-master/detect_onnx.py  \n",
            "   creating: RetinaFace-master/layers/\n",
            "  inflating: RetinaFace-master/layers/__init__.py  \n",
            "   creating: RetinaFace-master/layers/functions/\n",
            "  inflating: RetinaFace-master/layers/functions/prior_box.py  \n",
            "   creating: RetinaFace-master/layers/modules/\n",
            "  inflating: RetinaFace-master/layers/modules/__init__.py  \n",
            "  inflating: RetinaFace-master/layers/modules/multibox_loss.py  \n",
            "   creating: RetinaFace-master/models/\n",
            " extracting: RetinaFace-master/models/__init__.py  \n",
            "  inflating: RetinaFace-master/models/net.py  \n",
            "  inflating: RetinaFace-master/models/retinaface.py  \n",
            "  inflating: RetinaFace-master/test_fddb.py  \n",
            "  inflating: RetinaFace-master/test_widerface.py  \n",
            "  inflating: RetinaFace-master/train.py  \n",
            "   creating: RetinaFace-master/utils/\n",
            " extracting: RetinaFace-master/utils/__init__.py  \n",
            "  inflating: RetinaFace-master/utils/box_utils.py  \n",
            "   creating: RetinaFace-master/utils/nms/\n",
            " extracting: RetinaFace-master/utils/nms/__init__.py  \n",
            "  inflating: RetinaFace-master/utils/nms/py_cpu_nms.py  \n",
            "  inflating: RetinaFace-master/utils/timer.py  \n",
            "   creating: RetinaFace-master/widerface_evaluate/\n",
            "  inflating: RetinaFace-master/widerface_evaluate/README.md  \n",
            "  inflating: RetinaFace-master/widerface_evaluate/box_overlaps.pyx  \n",
            "  inflating: RetinaFace-master/widerface_evaluate/evaluation.py  \n",
            "   creating: RetinaFace-master/widerface_evaluate/ground_truth/\n",
            "  inflating: RetinaFace-master/widerface_evaluate/ground_truth/wider_easy_val.mat  \n",
            "  inflating: RetinaFace-master/widerface_evaluate/ground_truth/wider_face_val.mat  \n",
            "  inflating: RetinaFace-master/widerface_evaluate/ground_truth/wider_hard_val.mat  \n",
            "  inflating: RetinaFace-master/widerface_evaluate/ground_truth/wider_medium_val.mat  \n",
            "  inflating: RetinaFace-master/widerface_evaluate/setup.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the pretrained/ weight folder that you can download on GG Drive."
      ],
      "metadata": {
        "id": "qYFyZXAW1JZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Retinaface_model_v2-20251103T073704Z-1-001.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33cy3L_-kXlR",
        "outputId": "090f51c7-4162-4ea6-ae54-445477a76d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Retinaface_model_v2-20251103T073704Z-1-001.zip\n",
            "  inflating: Retinaface_model_v2/mobilenet0.25_Final.pth  \n",
            "  inflating: Retinaface_model_v2/mobilenetV1X0.25_pretrain.tar  \n",
            "  inflating: Retinaface_model_v2/Resnet50_Final.pth  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up to rebuild ONNX model"
      ],
      "metadata": {
        "id": "HOk_ZWNzuwpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply following changes on convert_to_onnx.py to rebuild ONNX"
      ],
      "metadata": {
        "id": "BPT4Xk0LveJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, these are some changes which are required to make the file able to run on Google Colab."
      ],
      "metadata": {
        "id": "2wyv-AcFNvL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 'RetinaFace-master' to sys.path if not already present.\n",
        "# This is necessary for Python to find 'models.retinaface' directly in this cell's context.\n",
        "project_root = 'RetinaFace-master'\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "# Attempt to get the module; if it exists, reload it.\n",
        "# This ensures the interpreter uses the updated file content.\n",
        "module_name = 'models.retinaface'\n",
        "if module_name in sys.modules:\n",
        "    importlib.reload(sys.modules[module_name])"
      ],
      "metadata": {
        "id": "nf2V6k1MwNgM"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8HD8eZ7HkQhA"
      },
      "outputs": [],
      "source": [
        "with open('RetinaFace-master/models/retinaface.py', 'r') as f:\n",
        "  content = f.read()\n",
        "\n",
        "# Replace the incorrect relative path with the correct one, relative to the current working directory\n",
        "# The traceback indicates the file currently contains './weights/mobilenetV1X0.25_pretrain.tar'\n",
        "new_content = content.replace(\n",
        "    \"./weights/mobilenetV1X0.25_pretrain.tar\",\n",
        "    \"RetinaFace-master/weights/mobilenetV1X0.25_pretrain.tar\"\n",
        ")\n",
        "\n",
        "with open('RetinaFace-master/models/retinaface.py', 'w') as f:\n",
        "  f.write(new_content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('RetinaFace-master/convert_to_onnx.py', 'r') as f:\n",
        "  content = f.read()\n",
        "\n",
        "# Replace the incorrect default path for --trained_model\n",
        "new_content = content.replace(\n",
        "    \"default='./weights/mobilenet0.25_Final.pth'\",\n",
        "    \"default='RetinaFace-master/weights/mobilenet0.25_Final.pth'\"\n",
        ")\n",
        "\n",
        "with open('RetinaFace-master/convert_to_onnx.py', 'w') as f:\n",
        "  f.write(new_content)"
      ],
      "metadata": {
        "id": "EFH6sahPluXz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second, apply this to build new ONNX model, here I opened the file on local machine and modify directly then upload here."
      ],
      "metadata": {
        "id": "awi9DWpzN0px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This one (apply it into the existing file)\n",
        "# dynamic_axes = {\"input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"}, \"bbox\": {1: \"batch_size\"}, \"confidence\": {1: \"batch_size\"}, \"landmark\": {1: \"batch_size\"}}"
      ],
      "metadata": {
        "id": "JdJmJ5nr4R5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, I did:\n",
        "+ Modified the code to make it be able to run in Google Colab\n",
        "+ Changed the line \"dynamic_axes\" (most important)\n",
        "→ The old version looks dynamic, but it isn’t.\n",
        "  Why:\n",
        "  + \"None\" is not a valid label for dynamic axes.\n",
        "\n",
        "  + PyTorch’s torch.onnx.export() only recognizes integer-to-string mapping, where the string is just a name label, e.g. \"batch_size\", \"height\", \"width\".\n",
        "  + It doesn’t accept \"None\" as a special keyword — so effectively, this dictionary is ignored.\n",
        "+ Used new name for new model.\n",
        "+ Create new ONNX file with new name"
      ],
      "metadata": {
        "id": "NfS62kf64mSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cat the file to see what I had changed"
      ],
      "metadata": {
        "id": "ArpkkNkn6tcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the updated content to verify\n",
        "with open('RetinaFace-master/convert_to_onnx.py', 'r') as f:\n",
        "  print(f.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQdvhQ2mv0h7",
        "outputId": "1da889be-1a4f-449f-a9a4-592c94240caa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from __future__ import print_function\n",
            "import os\n",
            "import argparse\n",
            "import torch\n",
            "import torch.backends.cudnn as cudnn\n",
            "import numpy as np\n",
            "from data import cfg_mnet, cfg_re50\n",
            "from layers.functions.prior_box import PriorBox\n",
            "from utils.nms.py_cpu_nms import py_cpu_nms\n",
            "import cv2\n",
            "from models.retinaface import RetinaFace\n",
            "from utils.box_utils import decode, decode_landm\n",
            "from utils.timer import Timer\n",
            "\n",
            "\n",
            "parser = argparse.ArgumentParser(description='Test')\n",
            "parser.add_argument('-m', '--trained_model', default='RetinaFace-master/weights/mobilenet0.25_Final.pth',\n",
            "                    type=str, help='Trained state_dict file path to open')\n",
            "parser.add_argument('--network', default='mobile0.25', help='Backbone network mobile0.25 or resnet50')\n",
            "parser.add_argument('--long_side', type=int, default=640, help='when origin_size is false, long_side is scaled size(320 or 640 for long side)')\n",
            "parser.add_argument('--cpu', action=\"store_true\", default=False, help='Use cpu inference')\n",
            "\n",
            "args = parser.parse_args()\n",
            "\n",
            "\n",
            "def check_keys(model, pretrained_state_dict):\n",
            "    ckpt_keys = set(pretrained_state_dict.keys())\n",
            "    model_keys = set(model.state_dict().keys())\n",
            "    used_pretrained_keys = model_keys & ckpt_keys\n",
            "    unused_pretrained_keys = ckpt_keys - model_keys\n",
            "    missing_keys = model_keys - ckpt_keys\n",
            "    print('Missing keys:{}'.format(len(missing_keys)))\n",
            "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
            "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
            "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
            "    return True\n",
            "\n",
            "\n",
            "def remove_prefix(state_dict, prefix):\n",
            "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
            "    print('remove prefix \\'{}\\''.format(prefix))\n",
            "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
            "    return {f(key): value for key, value in state_dict.items()}\n",
            "\n",
            "\n",
            "def load_model(model, pretrained_path, load_to_cpu):\n",
            "    print(\"load_to_cpu\", load_to_cpu)\n",
            "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
            "    if load_to_cpu:\n",
            "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
            "    else:\n",
            "        device = torch.cuda.current_device()\n",
            "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
            "    if \"state_dict\" in pretrained_dict.keys():\n",
            "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
            "    else:\n",
            "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
            "    check_keys(model, pretrained_dict)\n",
            "    model.load_state_dict(pretrained_dict, strict=False)\n",
            "    return model\n",
            "\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    torch.set_grad_enabled(False)\n",
            "    cfg = None\n",
            "    if args.network == \"mobile0.25\":\n",
            "        cfg = cfg_mnet\n",
            "    elif args.network == \"resnet50\":\n",
            "        cfg = cfg_re50\n",
            "    # net and model\n",
            "    net = RetinaFace(cfg=cfg, phase = 'test')\n",
            "    net = load_model(net, args.trained_model, args.cpu)\n",
            "    net.eval()\n",
            "    print('Finished loading model!')\n",
            "    print(net)\n",
            "    device = torch.device(\"cpu\" if args.cpu else \"cuda\")\n",
            "    net = net.to(device)\n",
            "\n",
            "    # ------------------------ export -----------------------------\n",
            "    output_onnx = 'FaceDetector_dynamic.onnx'\n",
            "    print(\"==> Exporting model to ONNX format at '{}'\".format(output_onnx))\n",
            "    input_names = [\"input\"]\n",
            "    output_names = [\"bbox\", \"confidence\", \"landmark\"]\n",
            "    inputs = torch.randn(1, 3, args.long_side, args.long_side).to(device)\n",
            "\n",
            "    dynamic_axes = {\"input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"}, \"bbox\": {1: \"batch_size\"}, \"confidence\": {1: \"batch_size\"}, \"landmark\": {1: \"batch_size\"}}\n",
            "\n",
            "    torch_out = torch.onnx.export(net, inputs, output_onnx, export_params=True, verbose=False,\n",
            "                                   input_names=input_names, output_names=output_names, opset_version=11,\n",
            "                                   dynamic_axes=dynamic_axes)\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rebuild command"
      ],
      "metadata": {
        "id": "VfuBZN3j28pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run RetinaFace-master/convert_to_onnx.py --trained_model RetinaFace-master/weights/Resnet50_Final.pth --network resnet50 --long_side 640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHE7c99Qv2hX",
        "outputId": "6cfaa5f8-46d6-47e6-94ad-9f6aacba2bcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 232MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load_to_cpu False\n",
            "Loading pretrained model from RetinaFace-master/weights/Resnet50_Final.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:456\n",
            "Finished loading model!\n",
            "RetinaFace(\n",
            "  (body): IntermediateLayerGetter(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fpn): FPN(\n",
            "    (output1): Sequential(\n",
            "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "    (output2): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "    (output3): Sequential(\n",
            "      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "    (merge1): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "    (merge2): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (ssh1): SSH(\n",
            "    (conv3X3): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv5X5_1): Sequential(\n",
            "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "    (conv5X5_2): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv7X7_2): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "    (conv7x7_3): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (ssh2): SSH(\n",
            "    (conv3X3): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv5X5_1): Sequential(\n",
            "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "    (conv5X5_2): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv7X7_2): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "    (conv7x7_3): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (ssh3): SSH(\n",
            "    (conv3X3): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv5X5_1): Sequential(\n",
            "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "    (conv5X5_2): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv7X7_2): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0, inplace=True)\n",
            "    )\n",
            "    (conv7x7_3): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (ClassHead): ModuleList(\n",
            "    (0-2): 3 x ClassHead(\n",
            "      (conv1x1): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (BboxHead): ModuleList(\n",
            "    (0-2): 3 x BboxHead(\n",
            "      (conv1x1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (LandmarkHead): ModuleList(\n",
            "    (0-2): 3 x LandmarkHead(\n",
            "      (conv1x1): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "==> Exporting model to ONNX format at 'FaceDetector.onnx'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/RetinaFace-master/convert_to_onnx.py:88: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch_out = torch.onnx.export(net, inputs, output_onnx, export_params=True, verbose=False,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Double check the code if needed."
      ],
      "metadata": {
        "id": "wYV8_VLNwvFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Clean up sys.path if we added it.\n",
        "# if project_root in sys.path:\n",
        "#     sys.path.remove(project_root)"
      ],
      "metadata": {
        "id": "vDy4mIkxmCBk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}